{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac4f4e70",
   "metadata": {},
   "source": [
    "# ü©∫ Classifica√ß√£o de Anomalias em ECG\n",
    "## Fibrila√ß√£o Atrial vs. Ritmo Sinusal Normal\n",
    "\n",
    "**Projeto:** Detec√ß√£o Autom√°tica de Arritmias Card√≠acas  \n",
    "**Bases de Dados:** PhysioNet MIT-BIH\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Objetivos do Projeto\n",
    "1. Extrair caracter√≠sticas avan√ßadas de sinais ECG\n",
    "2. Comparar ritmo normal vs. fibrila√ß√£o atrial\n",
    "3. Construir modelo de classifica√ß√£o robusto\n",
    "4. Avaliar poder discriminativo das features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1049c0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü´Ä Fundamentos: O que s√£o Anomalias Card√≠acas?\n",
    "\n",
    "### Ritmo Sinusal Normal (NSR)\n",
    "- Batimentos regulares e coordenados\n",
    "- Ondas P bem definidas\n",
    "- Intervalos R-R consistentes\n",
    "\n",
    "### Fibrila√ß√£o Atrial (AFib)\n",
    "- **Aus√™ncia de ondas P**: Contra√ß√£o atrial descoordenada\n",
    "- **Intervalos R-R irregulares**: Atividade el√©trica ca√≥tica\n",
    "- **Alta variabilidade**: Padr√£o imprevis√≠vel entre batimentos\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "### üí° Hip√≥tese Cient√≠fica\n",
    "A **Variabilidade da Frequ√™ncia Card√≠aca (HRV)** deve ser significativamente maior em pacientes com AFib devido √† irregularidade caracter√≠stica dos intervalos R-R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b741529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Importa√ß√£o de Bibliotecas\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from ecg_processor_V2 import process_records_in_windows, extract_comprehensive_features\n",
    "\n",
    "# Bibliotecas para Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "# Configura√ß√£o visual\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec262e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì• 1. Extra√ß√£o de Dados\n",
    "\n",
    "### Bases de Dados Utilizadas\n",
    "- **MIT-BIH Normal Sinus Rhythm Database (nsrdb)**: 5 pacientes saud√°veis\n",
    "- **MIT-BIH Atrial Fibrillation Database (afdb)**: 5 pacientes com AFib\n",
    "\n",
    "### Metodologia de Processamento\n",
    "- **Janelas de 30 segundos**: Segmenta√ß√£o n√£o-sobreposta\n",
    "- **Lead I**: Deriva√ß√£o √∫nica para consist√™ncia\n",
    "- **M√∫ltiplas amostras por paciente**: Cada janela = 1 amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2639c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o de diret√≥rios\n",
    "output_dir = 'data'\n",
    "basic_csv_path = os.path.join(output_dir, 'ecg_basic_features_ECG2.csv')\n",
    "comprehensive_csv_path = os.path.join(output_dir, 'ecg_comprehensive_features_ECG2.csv')\n",
    "\n",
    "# Criar diret√≥rio se n√£o existir\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d3dc8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî¨ 2. Pipeline de Processamento de Sinais\n",
    "\n",
    "### Etapas do Processamento\n",
    "\n",
    "#### 1Ô∏è‚É£ **Filtragem Passa-Banda**\n",
    "- Remove deriva da linha de base (0.5 Hz)\n",
    "- Elimina ru√≠do de alta frequ√™ncia (40 Hz)\n",
    "- Filtro Butterworth com fase zero\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "#### 2Ô∏è‚É£ **Detec√ß√£o de Picos R**\n",
    "- Identifica complexos QRS\n",
    "- Base para segmenta√ß√£o de batimentos\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "#### 3Ô∏è‚É£ **Features de HRV (Dom√≠nio do Tempo)**\n",
    "- `mean_rr`: Intervalo R-R m√©dio\n",
    "- `sdnn`: Desvio padr√£o dos intervalos NN\n",
    "- `rmssd`: Raiz quadrada da m√©dia das diferen√ßas sucessivas\n",
    "\n",
    "#### 4Ô∏è‚É£ **PCA - An√°lise de Componentes Principais**\n",
    "- Captura varia√ß√µes morfol√≥gicas dos batimentos\n",
    "- Redu√ß√£o de dimensionalidade\n",
    "- Identifica√ß√£o de padr√µes dominantes\n",
    "\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "#### 5Ô∏è‚É£ **ICA - An√°lise de Componentes Independentes**\n",
    "- Separa√ß√£o cega de fontes\n",
    "- Isola artefatos e sinais fisiol√≥gicos\n",
    "- **Potencial para detectar ondas fibrilat√≥rias**\n",
    "\n",
    "#### 6Ô∏è‚É£ **An√°lise Espectral**\n",
    "- Dom√≠nio da frequ√™ncia (LF/HF)\n",
    "- Balan√ßo auton√¥mico\n",
    "- ‚ö†Ô∏è **Limita√ß√£o**: Janelas de 30s s√£o curtas para an√°lise espectral completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34305a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Pipeline de Extra√ß√£o de Features ECG\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "reprocess = False  # Definir como True para reprocessar\n",
    "\n",
    "if reprocess or not os.path.exists(basic_csv_path) or not os.path.exists(comprehensive_csv_path):\n",
    "    # Lista de registros do PhysioNet\n",
    "    nsr_records = ['16265', '16272', '16420', '16483', '16539']\n",
    "    afib_records = ['04015', '04043', '04126', '04746', '04908']\n",
    "\n",
    "    # 1. Extrair Features B√°sicas de HRV\n",
    "    print(\"üìä Extraindo features b√°sicas de HRV...\")\n",
    "    nsr_basic = process_records_in_windows(nsr_records, 'nsrdb/1.0.0/', 'Normal', use_comprehensive=False)\n",
    "    afib_basic = process_records_in_windows(afib_records, 'afdb/1.0.0/', 'AFib', use_comprehensive=False)\n",
    "\n",
    "    df_basic = pd.DataFrame(nsr_basic + afib_basic)\n",
    "    df_basic.to_csv(basic_csv_path, index=False)\n",
    "    print(f\"‚úì Features b√°sicas: {len(df_basic)} janelas, {len(df_basic.columns)-3} features\")\n",
    "\n",
    "    # 2. Extrair Features Avan√ßadas (PCA, ICA, Espectral)\n",
    "    print(f\"\\nüß† Extraindo features avan√ßadas (PCA, ICA, Espectral)...\")\n",
    "\n",
    "    nsr_comprehensive = process_records_in_windows(nsr_records, 'nsrdb/1.0.0/', 'Normal', use_comprehensive=True)\n",
    "    afib_comprehensive = process_records_in_windows(afib_records, 'afdb/1.0.0/', 'AFib', use_comprehensive=True)\n",
    "\n",
    "    df_comprehensive = pd.DataFrame(nsr_comprehensive + afib_comprehensive)\n",
    "    df_comprehensive.to_csv(comprehensive_csv_path, index=False)\n",
    "    print(f\"‚úì Features avan√ßadas: {len(df_comprehensive)} janelas, {len(df_comprehensive.columns)-3} features\")\n",
    "\n",
    "    # Resumo\n",
    "    print(f\"\\nüìà RESUMO FINAL DE FEATURES\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Features B√°sicas HRV: {len([col for col in df_basic.columns if col not in ['record', 'window_id', 'label']])}\")\n",
    "    print(f\"Features Avan√ßadas: {len([col for col in df_comprehensive.columns if col not in ['record', 'window_id', 'label']])}\")\n",
    "    print(f\"Fator de Aumento: {len(df_comprehensive.columns) / len(df_basic.columns):.1f}x mais features\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Pronto para an√°lise!\")\n",
    "else:\n",
    "    print('‚úì Arquivos CSV j√° existem!')\n",
    "    print(f\"‚úÖ Pronto para an√°lise!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf29a8c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß† 3. Por que PCA, ICA e An√°lise Espectral?\n",
    "\n",
    "### üéØ PCA (An√°lise de Componentes Principais)\n",
    "**Objetivo:** Redu√ß√£o de dimensionalidade e extra√ß√£o de padr√µes morfol√≥gicos\n",
    "\n",
    "- ‚úÖ **Captura varia√ß√µes importantes** na morfologia dos batimentos\n",
    "- ‚úÖ **Redu√ß√£o de ru√≠do**: Foca nas dire√ß√µes de maior vari√¢ncia\n",
    "- ‚úÖ **Reconhecimento de padr√µes**: Diferentes condi√ß√µes card√≠acas = padr√µes morfol√≥gicos distintos\n",
    "- ‚úÖ **Compress√£o de dados**: Representa formas complexas com menos dimens√µes\n",
    "\n",
    "### üéØ ICA (An√°lise de Componentes Independentes)\n",
    "**Objetivo:** Separa√ß√£o cega de fontes e remo√ß√£o de artefatos\n",
    "\n",
    "- ‚úÖ **Separa√ß√£o de fontes mistas**: Isola sinais fisiol√≥gicos sobrepostos\n",
    "- ‚úÖ **Remo√ß√£o de artefatos**: Separa ru√≠do muscular, deriva de linha de base\n",
    "- ‚úÖ **An√°lise multi-processo**: Revela atividades card√≠acas sobrepostas\n",
    "- ‚úÖ **Detec√ß√£o de arritmias**: Diferentes arritmias = padr√µes independentes √∫nicos\n",
    "\n",
    "### üéØ An√°lise Espectral\n",
    "**Objetivo:** An√°lise no dom√≠nio da frequ√™ncia\n",
    "\n",
    "- ‚úÖ **Dom√≠nio da frequ√™ncia**: Analisa HRV em diferentes bandas\n",
    "- ‚úÖ **Fun√ß√£o auton√¥mica**: Raz√£o LF/HF indica balan√ßo simp√°tico vs. parassimp√°tico\n",
    "- ‚úÖ **Relev√¢ncia cl√≠nica**: Marcadores estabelecidos para avalia√ß√£o da sa√∫de card√≠aca\n",
    "\n",
    "‚ö†Ô∏è **Nota sobre Limita√ß√µes**: A raz√£o LF/HF requer janelas de 5 minutos (padr√£o). Janelas de 30s s√£o insuficientes para an√°lise espectral robusta das bandas de baixa frequ√™ncia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcded6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados processados\n",
    "nsr_records = ['16265', '16272', '16420', '16483', '16539']\n",
    "afib_records = ['04015', '04043', '04126', '04746', '04908']\n",
    "\n",
    "df_basic = pd.read_csv(basic_csv_path)\n",
    "df_comprehensive = pd.read_csv(comprehensive_csv_path)\n",
    "\n",
    "print(\"‚úÖ Dados carregados com sucesso!\")\n",
    "print(f\"üìä Shape do dataset: {df_comprehensive.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c772145",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä 4. An√°lise Explorat√≥ria do Dataset\n",
    "\n",
    "### Vis√£o Geral dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56dc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise do Dataset\n",
    "print(\"üìä AN√ÅLISE ABRANGENTE DO DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Informa√ß√µes b√°sicas\n",
    "print(f\"Dimens√µes do Dataset: {df_comprehensive.shape}\")\n",
    "print(f\"Janelas Normais: {len(df_comprehensive[df_comprehensive['label'] == 'Normal'])}\")\n",
    "print(f\"Janelas AFib: {len(df_comprehensive[df_comprehensive['label'] == 'AFib'])}\")\n",
    "\n",
    "# Categorias de features\n",
    "feature_categories = {\n",
    "    'HRV (Dom√≠nio do Tempo)': [col for col in df_comprehensive.columns if any(hrv in col for hrv in ['mean_rr', 'sdnn', 'rmssd', 'pnn50', 'hr_mean'])],\n",
    "    'PCA (Morfol√≥gicas)': [col for col in df_comprehensive.columns if 'pca_' in col],\n",
    "    'ICA (Fontes Independentes)': [col for col in df_comprehensive.columns if 'ica_' in col],\n",
    "    'Espectral (Dom√≠nio da Frequ√™ncia)': [col for col in df_comprehensive.columns if 'spectral_' in col],\n",
    "    'Qualidade do Sinal': [col for col in df_comprehensive.columns if any(qual in col for qual in ['signal_quality', 'num_heartbeats', 'beat_detection'])]\n",
    "}\n",
    "\n",
    "print(f\"\\nüìÇ Categorias de Features:\")\n",
    "for category, features in feature_categories.items():\n",
    "    print(f\"  ‚Ä¢ {category}: {len(features)} features\")\n",
    "    if len(features) > 0:\n",
    "        example_features = features[:3] if len(features) >= 3 else features\n",
    "        print(f\"    Exemplos: {', '.join(example_features)}\")\n",
    "\n",
    "# Verificar valores faltantes\n",
    "missing_counts = df_comprehensive.isnull().sum()\n",
    "features_with_missing = missing_counts[missing_counts > 0]\n",
    "\n",
    "if len(features_with_missing) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Features com valores faltantes:\")\n",
    "    for feature, count in features_with_missing.items():\n",
    "        print(f\"  ‚Ä¢ {feature}: {count} faltantes ({count/len(df_comprehensive)*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Nenhum valor faltante detectado!\")\n",
    "\n",
    "# Estat√≠sticas b√°sicas\n",
    "print(f\"\\nüìà Estat√≠sticas do Dataset:\")\n",
    "print(f\"  ‚Ä¢ Total de features extra√≠das: {len(df_comprehensive.columns) - 3}\")\n",
    "print(f\"  ‚Ä¢ Total de janelas v√°lidas: {len(df_comprehensive)}\")\n",
    "print(f\"  ‚Ä¢ Taxa de sucesso: {len(df_comprehensive) / (len(nsr_records + afib_records) * 2 * 60):.1f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset pronto para visualiza√ß√£o e an√°lise!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614cb9e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà 5. Visualiza√ß√£o de Features Avan√ßadas\n",
    "\n",
    "### Compara√ß√£o: Normal vs. AFib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o Abrangente de Features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('An√°lise de Features ECG: Normal vs AFib', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. HRV Tradicional - RMSSD\n",
    "sns.boxplot(data=df_comprehensive, x='label', y='rmssd', hue='label', ax=axes[0,0], palette='viridis', legend=False)\n",
    "axes[0,0].set_title('RMSSD (HRV Tradicional)', fontweight='bold')\n",
    "axes[0,0].set_ylabel('RMSSD (ms)')\n",
    "axes[0,0].set_xlabel('Tipo de Ritmo')\n",
    "\n",
    "# 2. Vari√¢ncia Explicada pelo PCA\n",
    "pca_var_cols = [col for col in df_comprehensive.columns if 'pca_var_ratio_1' in col]\n",
    "if pca_var_cols:\n",
    "    sns.boxplot(data=df_comprehensive, x='label', y=pca_var_cols[0], hue='label', ax=axes[0,1], palette='plasma', legend=False)\n",
    "    axes[0,1].set_title('Vari√¢ncia do 1¬∫ Componente PCA', fontweight='bold')\n",
    "    axes[0,1].set_ylabel('Raz√£o de Vari√¢ncia Explicada')\n",
    "    axes[0,1].set_xlabel('Tipo de Ritmo')\n",
    "\n",
    "# 3. Energia ICA\n",
    "ica_energy_cols = [col for col in df_comprehensive.columns if 'ica_ic1_energy' in col]\n",
    "if ica_energy_cols:\n",
    "    sns.boxplot(data=df_comprehensive, x='label', y=ica_energy_cols[0], hue='label', ax=axes[0,2], palette='coolwarm', legend=False)\n",
    "    axes[0,2].set_title('Energia do 1¬∫ Componente ICA', fontweight='bold')\n",
    "    axes[0,2].set_ylabel('Energia')\n",
    "    axes[0,2].set_xlabel('Tipo de Ritmo')\n",
    "    axes[0,2].set_yscale('log')\n",
    "\n",
    "# 4. Raz√£o LF/HF Espectral\n",
    "spectral_ratio_cols = [col for col in df_comprehensive.columns if 'spectral_lf_hf_ratio' in col]\n",
    "if spectral_ratio_cols:\n",
    "    sns.violinplot(data=df_comprehensive, x='label', y=spectral_ratio_cols[0], hue='label', ax=axes[1,0], palette='Set2', legend=False)\n",
    "    axes[1,0].set_title('Raz√£o LF/HF (Balan√ßo Auton√¥mico)', fontweight='bold')\n",
    "    axes[1,0].set_ylabel('Raz√£o LF/HF')\n",
    "    axes[1,0].set_xlabel('Tipo de Ritmo')\n",
    "\n",
    "# 5. Scatter PCA vs ICA\n",
    "pca_mean_cols = [col for col in df_comprehensive.columns if 'pca_pc1_mean' in col]\n",
    "ica_mean_cols = [col for col in df_comprehensive.columns if 'ica_ic1_mean' in col]\n",
    "if pca_mean_cols and ica_mean_cols:\n",
    "    sns.scatterplot(data=df_comprehensive, x=pca_mean_cols[0], y=ica_mean_cols[0], \n",
    "                   hue='label', ax=axes[1,1], alpha=0.7, palette='Set1')\n",
    "    axes[1,1].set_title('Features PCA vs ICA', fontweight='bold')\n",
    "    axes[1,1].set_xlabel('M√©dia PC1 (PCA)')\n",
    "    axes[1,1].set_ylabel('M√©dia IC1 (ICA)')\n",
    "    axes[1,1].legend(title='Tipo de Ritmo')\n",
    "\n",
    "# 6. Qualidade do Sinal (SNR)\n",
    "signal_quality_cols = [col for col in df_comprehensive.columns if 'signal_quality_snr' in col]\n",
    "if signal_quality_cols:\n",
    "    sns.histplot(data=df_comprehensive, x=signal_quality_cols[0], hue='label', \n",
    "                ax=axes[1,2], alpha=0.7, bins=30)\n",
    "    axes[1,2].set_title('Qualidade do Sinal (SNR)', fontweight='bold')\n",
    "    axes[1,2].set_xlabel('Raz√£o Sinal-Ru√≠do')\n",
    "    axes[1,2].set_ylabel('Contagem')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualiza√ß√µes geradas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4dc5e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä 6. An√°lise Estat√≠stica: Poder Discriminativo\n",
    "\n",
    "### Teste de Mann-Whitney U\n",
    "- **Objetivo**: Identificar features mais discriminativas\n",
    "- **M√©todo**: Teste n√£o-param√©trico (n√£o assume normalidade)\n",
    "- **Interpreta√ß√£o**: \n",
    "  - `p < 0.05`: Diferen√ßa estatisticamente significativa\n",
    "  - `d` (Cohen's d): Tamanho do efeito (0.2=pequeno, 0.5=m√©dio, 0.8+=grande)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d1deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise Estat√≠stica de Features\n",
    "from scipy import stats\n",
    "\n",
    "print(\"üìä AN√ÅLISE ESTAT√çSTICA DE FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Usando teste Mann-Whitney U para identificar features mais discriminativas\")\n",
    "print(\"p < 0.05 indica diferen√ßa significativa entre Normal e AFib\")\n",
    "\n",
    "# Separar dados Normal e AFib\n",
    "normal_data = df_comprehensive[df_comprehensive['label'] == 'Normal']\n",
    "afib_data = df_comprehensive[df_comprehensive['label'] == 'AFib']\n",
    "\n",
    "# Analisar grupos de features\n",
    "results = []\n",
    "for category, features in feature_categories.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    print(\"-\" * (len(category) + 4))\n",
    "    \n",
    "    significant_features = 0\n",
    "    for feature in features:\n",
    "        if feature in df_comprehensive.columns:\n",
    "            normal_values = normal_data[feature].dropna()\n",
    "            afib_values = afib_data[feature].dropna()\n",
    "            \n",
    "            if len(normal_values) > 0 and len(afib_values) > 0:\n",
    "                # Teste Mann-Whitney U (n√£o-param√©trico)\n",
    "                statistic, p_value = stats.mannwhitneyu(normal_values, afib_values, alternative='two-sided')\n",
    "                    \n",
    "                # Tamanho do efeito (Cohen's d)\n",
    "                pooled_std = np.sqrt((normal_values.var() + afib_values.var()) / 2)\n",
    "                cohens_d = abs(normal_values.mean() - afib_values.mean()) / pooled_std if pooled_std > 0 else 0\n",
    "                    \n",
    "                significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"\"\n",
    "                    \n",
    "                print(f\"  {feature:<30} p={p_value:.2e} d={cohens_d:.3f} {significance}\")\n",
    "                    \n",
    "                if p_value < 0.05:\n",
    "                    significant_features += 1\n",
    "                    \n",
    "                results.append({\n",
    "                    'category': category,\n",
    "                    'feature': feature,\n",
    "                    'p_value': p_value,\n",
    "                    'effect_size': cohens_d,\n",
    "                    'significant': p_value < 0.05\n",
    "                })\n",
    "    \n",
    "    print(f\"  ‚Üí {significant_features}/{len([f for f in features if f in df_comprehensive.columns])} features significativamente diferentes\")\n",
    "\n",
    "# Resumo dos resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "if len(df_results) > 0:\n",
    "    print(f\"\\nüìà RESUMO ESTAT√çSTICO\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Estat√≠sticas por grupo\n",
    "    group_stats = df_results.groupby('category').agg({\n",
    "        'significant': ['count', 'sum'],\n",
    "        'effect_size': ['mean', 'max']\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"Desempenho por Categoria:\")\n",
    "    for category in group_stats.index:\n",
    "        total = group_stats.loc[category, ('significant', 'count')]\n",
    "        significant = group_stats.loc[category, ('significant', 'sum')]\n",
    "        mean_effect = group_stats.loc[category, ('effect_size', 'mean')]\n",
    "        max_effect = group_stats.loc[category, ('effect_size', 'max')]\n",
    "        \n",
    "        print(f\"  {category:<30}: {significant:2d}/{total:2d} significativas, d m√©dio={mean_effect:.3f}, d m√°x={max_effect:.3f}\")\n",
    "    \n",
    "    # Top features\n",
    "    top_features = df_results.nlargest(10, 'effect_size')\n",
    "    print(f\"\\nüèÜ Top 10 Features Mais Discriminativas:\")\n",
    "    for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "        status = \"‚úì\" if row['significant'] else \"‚úó\"\n",
    "        print(f\"  {i:2d}. {row['feature']:<30} d={row['effect_size']:.3f} {status}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Total: {df_results['significant'].sum()}/{len(df_results)} features mostram diferen√ßas significativas\")\n",
    "    best_feature = df_results.loc[df_results['effect_size'].idxmax()]\n",
    "    print(f\"ü•á Melhor feature: {best_feature['feature']} (d={best_feature['effect_size']:.3f})\")\n",
    "else:\n",
    "    print(\"‚ùå Nenhum resultado para analisar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54cd896",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ 7. Classifica√ß√£o com XGBoost\n",
    "\n",
    "### Por que XGBoost?\n",
    "\n",
    "‚úÖ **Vantagens para Dados M√©dicos**:\n",
    "- Lida bem com features mistas (HRV + morfol√≥gicas)\n",
    "- Regulariza√ß√£o integrada (previne overfitting)\n",
    "- Interpretabilidade via import√¢ncia de features\n",
    "- Excelente desempenho em dados tabulares\n",
    "\n",
    "### Features Selecionadas\n",
    "- **RMSSD**: Medida tradicional de HRV\n",
    "- **Vari√¢ncia PCA**: Captura varia√ß√µes morfol√≥gicas\n",
    "- **Energia ICA**: Poss√≠vel assinatura de ondas fibrilat√≥rias\n",
    "- **Outras features discriminativas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3abab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para XGBoost\n",
    "print(\"üöÄ PREPARANDO DADOS PARA CLASSIFICA√á√ÉO XGBOOST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Dimens√µes do dataset: {df_comprehensive.shape}\")\n",
    "\n",
    "# Features-chave para classifica√ß√£o\n",
    "key_features = []\n",
    "\n",
    "# 1. RMSSD (HRV)\n",
    "if 'rmssd' in df_comprehensive.columns:\n",
    "    key_features.append('rmssd')\n",
    "    print(f\"‚úì Feature RMSSD encontrada\")\n",
    "\n",
    "# 2. Vari√¢ncia do 1¬∫ Componente PCA\n",
    "pca_var_cols = [col for col in df_comprehensive.columns if 'pca_var_ratio_1' in col]\n",
    "if pca_var_cols:\n",
    "    key_features.append(pca_var_cols[0])\n",
    "    print(f\"‚úì Vari√¢ncia PCA encontrada: {pca_var_cols[0]}\")\n",
    "\n",
    "# Features discriminativas adicionais\n",
    "additional_features = []\n",
    "for feature in ['sdnn', 'mean_rr', 'pca_pc1_mean', 'spectral_lf_hf_ratio', 'ica_ic3_energy']:\n",
    "    if feature in df_comprehensive.columns:\n",
    "        additional_features.append(feature)\n",
    "\n",
    "print(f\"\\nüìä Features prim√°rias: {key_features}\")\n",
    "print(f\"üìä Features adicionais: {additional_features}\")\n",
    "\n",
    "# Combinar features\n",
    "all_features = key_features + additional_features\n",
    "print(f\"\\n‚úÖ Total de features para classifica√ß√£o: {len(all_features)}\")\n",
    "print(f\"üìã Lista de features: {all_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementa√ß√£o da Classifica√ß√£o XGBoost\n",
    "print(\"ü§ñ CLASSIFICA√á√ÉO DE ANOMALIAS ECG COM XGBOOST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Preparar dataset\n",
    "X = df_comprehensive[all_features].copy()\n",
    "y = df_comprehensive['label'].copy()\n",
    "\n",
    "# Codificar labels (XGBoost precisa de labels num√©ricos)\n",
    "label_mapping = {'Normal': 0, 'AFib': 1}\n",
    "y_encoded = y.map(label_mapping)\n",
    "\n",
    "print(f\"Dimens√µes: {X.shape}\")\n",
    "print(f\"Distribui√ß√£o de classes:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Tratar valores faltantes\n",
    "missing_count = X.isnull().sum().sum()\n",
    "if missing_count > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Tratando {missing_count} valores faltantes...\")\n",
    "    X = X.fillna(X.median())\n",
    "else:\n",
    "    print(\"\\n‚úÖ Nenhum valor faltante detectado!\")\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Conjunto de treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"üìä Conjunto de teste: {X_test.shape[0]} amostras\")\n",
    "print(f\"   Treino - Normal: {np.sum(y_train==0)}, AFib: {np.sum(y_train==1)}\")\n",
    "print(f\"   Teste  - Normal: {np.sum(y_test==0)}, AFib: {np.sum(y_test==1)}\")\n",
    "\n",
    "# Normaliza√ß√£o\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Inicializar XGBoost com par√¢metros otimizados para dados m√©dicos\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo XGBoost inicializado com par√¢metros otimizados para dados m√©dicos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999a783",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä 8. Treinamento e Avalia√ß√£o do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfdbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar e Avaliar Modelo\n",
    "print(\"üéì TREINANDO MODELO XGBOOST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Treinar modelo\n",
    "print(\"Treinando classificador XGBoost...\")\n",
    "xgb_classifier.fit(X_train_scaled, y_train)\n",
    "print(\"‚úÖ Treinamento conclu√≠do!\")\n",
    "\n",
    "# Fazer predi√ß√µes\n",
    "y_pred = xgb_classifier.predict(X_test_scaled)\n",
    "y_pred_proba = xgb_classifier.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calcular m√©tricas\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nüìä M√âTRICAS DE DESEMPENHO DO MODELO\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üéØ Acur√°cia: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "print(f\"üìà AUC Score: {auc_score:.3f}\")\n",
    "\n",
    "# Relat√≥rio de classifica√ß√£o detalhado\n",
    "print(f\"\\nüìã Relat√≥rio de Classifica√ß√£o Detalhado:\")\n",
    "target_names = ['Normal', 'AFib']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# Matriz de Confus√£o\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nüî¢ Matriz de Confus√£o:\")\n",
    "print(f\"                Predito\")\n",
    "print(f\"                Normal  AFib\")\n",
    "print(f\"Real Normal     {cm[0,0]:6d} {cm[0,1]:5d}\")\n",
    "print(f\"     AFib       {cm[1,0]:6d} {cm[1,1]:5d}\")\n",
    "\n",
    "# Valida√ß√£o cruzada\n",
    "print(f\"\\nüîÑ RESULTADOS DA VALIDA√á√ÉO CRUZADA\")\n",
    "print(\"=\" * 40)\n",
    "cv_scores = cross_val_score(xgb_classifier, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"5-Fold CV AUC: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n",
    "print(f\"Folds individuais: {[f'{score:.3f}' for score in cv_scores]}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Classifica√ß√£o XGBoost conclu√≠da com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc1297",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà 9. An√°lise de Import√¢ncia de Features\n",
    "\n",
    "### Interpreta√ß√£o do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3768b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de Import√¢ncia de Features\n",
    "print(\"üîç AN√ÅLISE DE IMPORT√ÇNCIA DE FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Obter import√¢ncia do XGBoost\n",
    "feature_importance = xgb_classifier.feature_importances_\n",
    "feature_names = all_features\n",
    "\n",
    "# Criar dataframe de import√¢ncia\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"üèÜ Top 10 Features Mais Importantes:\")\n",
    "print(\"-\" * 40)\n",
    "for i, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):\n",
    "    print(f\"{i:2d}. {row['feature']:<25} {row['importance']:.4f}\")\n",
    "\n",
    "# Visualiza√ß√µes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Resultados da Classifica√ß√£o XGBoost - ECG', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Import√¢ncia de Features\n",
    "top_features = importance_df.head(10)\n",
    "sns.barplot(data=top_features, y='feature', x='importance', ax=axes[0,0], palette='viridis')\n",
    "axes[0,0].set_title('Top 10 Features Mais Importantes', fontweight='bold')\n",
    "axes[0,0].set_xlabel('Score de Import√¢ncia')\n",
    "\n",
    "# 2. Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "axes[0,1].plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {auc_score:.3f})')\n",
    "axes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Classificador Aleat√≥rio')\n",
    "axes[0,1].set_xlim([0.0, 1.0])\n",
    "axes[0,1].set_ylim([0.0, 1.05])\n",
    "axes[0,1].set_xlabel('Taxa de Falsos Positivos')\n",
    "axes[0,1].set_ylabel('Taxa de Verdadeiros Positivos')\n",
    "axes[0,1].set_title('Curva ROC', fontweight='bold')\n",
    "axes[0,1].legend(loc=\"lower right\")\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Heatmap da Matriz de Confus√£o\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1,0],\n",
    "            xticklabels=['Normal', 'AFib'], yticklabels=['Normal', 'AFib'])\n",
    "axes[1,0].set_title('Matriz de Confus√£o', fontweight='bold')\n",
    "axes[1,0].set_xlabel('Label Predito')\n",
    "axes[1,0].set_ylabel('Label Verdadeiro')\n",
    "\n",
    "# 4. Distribui√ß√£o de Probabilidades de Predi√ß√£o\n",
    "prob_df = pd.DataFrame({\n",
    "    'probability': y_pred_proba,\n",
    "    'true_label': ['Normal' if x == 0 else 'AFib' for x in y_test]\n",
    "})\n",
    "sns.histplot(data=prob_df, x='probability', hue='true_label', ax=axes[1,1], alpha=0.7, bins=20)\n",
    "axes[1,1].set_title('Distribui√ß√£o de Probabilidades de Predi√ß√£o', fontweight='bold')\n",
    "axes[1,1].set_xlabel('Probabilidade AFib')\n",
    "axes[1,1].set_ylabel('Contagem')\n",
    "axes[1,1].axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='Limiar de Decis√£o')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lise de features-chave\n",
    "print(f\"\\nüîë AN√ÅLISE DE FEATURES-CHAVE\")\n",
    "print(\"=\" * 40)\n",
    "rmssd_importance = importance_df[importance_df['feature'] == 'rmssd']['importance'].values\n",
    "pca_var_importance = importance_df[importance_df['feature'].str.contains('pca_var_ratio_1', na=False)]['importance'].values\n",
    "\n",
    "if len(rmssd_importance) > 0:\n",
    "    print(f\"RMSSD import√¢ncia: {rmssd_importance[0]:.4f} (Rank: {importance_df[importance_df['feature'] == 'rmssd'].index[0] + 1})\")\n",
    "if len(pca_var_importance) > 0:\n",
    "    pca_feature_name = importance_df[importance_df['feature'].str.contains('pca_var_ratio_1', na=False)]['feature'].iloc[0]\n",
    "    print(f\"Vari√¢ncia PCA import√¢ncia: {pca_var_importance[0]:.4f} (Rank: {importance_df[importance_df['feature'] == pca_feature_name].index[0] + 1})\")\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo classifica anomalias ECG com {accuracy:.1%} de acur√°cia!\")\n",
    "print(f\"‚úÖ Poder discriminativo forte (AUC: {auc_score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e5d1e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí° 10. Insights Cl√≠nicos\n",
    "\n",
    "### Interpreta√ß√£o dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpreta√ß√£o do Modelo e Insights Cl√≠nicos\n",
    "print(\"üî¨ INTERPRETA√á√ÉO DO MODELO & INSIGHTS CL√çNICOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analisar desempenho espec√≠fico de RMSSD\n",
    "if 'rmssd' in all_features:\n",
    "    normal_rmssd = df_comprehensive[df_comprehensive['label'] == 'Normal']['rmssd']\n",
    "    afib_rmssd = df_comprehensive[df_comprehensive['label'] == 'AFib']['rmssd']\n",
    "    \n",
    "    print(f\"üìä An√°lise RMSSD:\")\n",
    "    print(f\"  Ritmo Normal - M√©dia: {normal_rmssd.mean():.2f} ms, Desvio: {normal_rmssd.std():.2f} ms\")\n",
    "    print(f\"  Ritmo AFib   - M√©dia: {afib_rmssd.mean():.2f} ms, Desvio: {afib_rmssd.std():.2f} ms\")\n",
    "    print(f\"  Diferen√ßa: {abs(afib_rmssd.mean() - normal_rmssd.mean()):.2f} ms\")\n",
    "    print(f\"  üí° Insight cl√≠nico: {'AFib mostra maior variabilidade' if afib_rmssd.mean() > normal_rmssd.mean() else 'Normal mostra maior variabilidade'}\")\n",
    "\n",
    "# Encontrar feature PCA\n",
    "pca_var_cols = [col for col in all_features if 'pca_var_ratio_1' in col]\n",
    "if pca_var_cols:\n",
    "    pca_feature = pca_var_cols[0]\n",
    "    normal_pca = df_comprehensive[df_comprehensive['label'] == 'Normal'][pca_feature]\n",
    "    afib_pca = df_comprehensive[df_comprehensive['label'] == 'AFib'][pca_feature]\n",
    "    \n",
    "    print(f\"\\nüìä An√°lise Vari√¢ncia 1¬∫ Componente PCA:\")\n",
    "    print(f\"  Ritmo Normal - M√©dia: {normal_pca.mean():.4f}, Desvio: {normal_pca.std():.4f}\")\n",
    "    print(f\"  Ritmo AFib   - M√©dia: {afib_pca.mean():.4f}, Desvio: {afib_pca.std():.4f}\")\n",
    "    print(f\"  Diferen√ßa: {abs(afib_pca.mean() - normal_pca.mean()):.4f}\")\n",
    "    print(f\"  üí° Insight cl√≠nico: {'AFib mostra mais varia√ß√£o morfol√≥gica' if afib_pca.mean() > normal_pca.mean() else 'Normal mostra mais varia√ß√£o morfol√≥gica'}\")\n",
    "\n",
    "# An√°lise de confian√ßa das predi√ß√µes\n",
    "high_confidence_correct = np.sum((y_pred_proba > 0.8) & (y_pred == y_test)) + np.sum((y_pred_proba < 0.2) & (y_pred == y_test))\n",
    "high_confidence_total = np.sum((y_pred_proba > 0.8) | (y_pred_proba < 0.2))\n",
    "medium_confidence_total = np.sum((y_pred_proba >= 0.4) & (y_pred_proba <= 0.6))\n",
    "\n",
    "print(f\"\\nüìà AN√ÅLISE DE CONFIAN√áA DAS PREDI√á√ïES\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Predi√ß√µes de alta confian√ßa (>80% ou <20%): {high_confidence_total}/{len(y_test)} ({high_confidence_total/len(y_test)*100:.1f}%)\")\n",
    "print(f\"Acur√°cia em alta confian√ßa: {high_confidence_correct/high_confidence_total*100 if high_confidence_total > 0 else 0:.1f}%\")\n",
    "print(f\"Predi√ß√µes incertas (40-60%): {medium_confidence_total}/{len(y_test)} ({medium_confidence_total/len(y_test)*100:.1f}%)\")\n",
    "\n",
    "# Resumo para suporte √† decis√£o cl√≠nica\n",
    "print(f\"\\nüè• RESUMO PARA SUPORTE √Ä DECIS√ÉO CL√çNICA\")\n",
    "print(\"=\" * 50)\n",
    "quality = 'Excelente' if accuracy > 0.9 else 'Bom' if accuracy > 0.8 else 'Moderado'\n",
    "auc_quality = 'Excelente' if auc_score > 0.9 else 'Bom' if auc_score > 0.8 else 'Moderado'\n",
    "print(f\"‚úÖ Acur√°cia do Modelo: {accuracy:.1%} - {quality}\")\n",
    "print(f\"‚úÖ AUC Score: {auc_score:.3f} - Poder discriminativo {auc_quality}\")\n",
    "print(f\"‚úÖ Utilidade Cl√≠nica: Pode auxiliar em triagem automatizada de AFib a partir de dados ECG\")\n",
    "\n",
    "# Prontid√£o para deploy\n",
    "print(f\"\\nüöÄ PRONTID√ÉO PARA IMPLANTA√á√ÉO\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"‚úÖ Dataset balanceado: Normal ({np.sum(y_encoded == 0)}) vs AFib ({np.sum(y_encoded == 1)}) amostras\")\n",
    "print(f\"‚úÖ Valida√ß√£o cruzada: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f} (desempenho consistente)\")\n",
    "print(f\"‚úÖ Estabilidade de features: {len(all_features)} features robustas extra√≠das\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a1dca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ 11. Conclus√µes Principais\n",
    "\n",
    "### üèÜ Resultados Alcan√ßados\n",
    "\n",
    "#### Desempenho do Modelo\n",
    "- ‚úÖ **Acur√°cia elevada**: Classifica√ß√£o precisa entre Normal e AFib\n",
    "- ‚úÖ **AUC excelente**: Forte poder discriminativo\n",
    "- ‚úÖ **Valida√ß√£o cruzada consistente**: Modelo robusto e generaliza bem\n",
    "\n",
    "#### Features Mais Importantes\n",
    "\n",
    "**1. ü•á ICA IC3 Energy - A Estrela do Projeto**\n",
    "- **Cohen's d astron√¥mico**: Separa√ß√£o quase perfeita entre classes\n",
    "- **Explica√ß√£o prov√°vel**: O 3¬∫ componente independente isolou as **ondas fibrilat√≥rias** ('ondas f')\n",
    "- **Analogia**: Como um engenheiro de som que consegue isolar o ru√≠do de fundo em uma grava√ß√£o\n",
    "\n",
    "**2. ü•à Vari√¢ncias PCA (Componentes 3, 4 e 5)**\n",
    "- Capturam varia√ß√µes morfol√≥gicas significativas\n",
    "- AFib apresenta maior variabilidade na forma dos batimentos\n",
    "\n",
    "**3. ü•â Features HRV Tradicionais**\n",
    "- RMSSD, SDNN, Mean RR: Todas significativas\n",
    "- Confirmam a hip√≥tese: AFib tem maior irregularidade\n",
    "\n",
    "#### Por que ICA IC3 Energy Funcionou T√£o Bem?\n",
    "\n",
    "**Analogia Musical üé∂**\n",
    "\n",
    "**Ritmo Normal**: Banda tocando limpo\n",
    "- ü•Å Bateria (QRS) - forte e dominante\n",
    "- üé∏ Baixo (onda T) - r√≠tmico\n",
    "\n",
    "**Ritmo AFib**: Mesma banda + pandeiro ca√≥tico ao fundo\n",
    "- ü•Å Bateria (QRS)\n",
    "- üé∏ Baixo (onda T)  \n",
    "- ü™ò **Pandeiro ca√≥tico (ondas fibrilat√≥rias)** ‚Üê ICA isolou isto!\n",
    "\n",
    "**ICA separou as \"faixas de √°udio\":**\n",
    "- IC1: Provavelmente isolou o QRS (bateria)\n",
    "- IC2: Talvez a onda T (baixo)\n",
    "- **IC3: ISOLOU O PANDEIRO CA√ìTICO** (ondas fibrilat√≥rias)\n",
    "\n",
    "A energia do IC3 mede o \"volume\" desse pandeiro:\n",
    "- **Normal**: Quase sil√™ncio (energia baixa)\n",
    "- **AFib**: Barulho constante (energia alta)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è 12. Limita√ß√µes e Trabalhos Futuros\n",
    "\n",
    "### Limita√ß√µes Identificadas\n",
    "\n",
    "#### 1. Tamanho da Amostra\n",
    "- **Atual**: 10 pacientes (5 Normal + 5 AFib)\n",
    "- **Recomenda√ß√£o**: Utilizar todos os registros dispon√≠veis\n",
    "  - nsrdb: 18 pacientes\n",
    "  - afdb: 23 pacientes\n",
    "- **Benef√≠cio**: Maior diversidade e melhor generaliza√ß√£o\n",
    "\n",
    "#### 2. Janelas de 30 Segundos\n",
    "- ‚úÖ **Vantagens**: Computacionalmente eficiente, adequado para HRV e morfologia\n",
    "- ‚ö†Ô∏è **Limita√ß√µes**: Insuficiente para an√°lise espectral completa\n",
    "  - N√£o resolve bem a banda VLF (< 0.04 Hz)\n",
    "  - LF/HF ratio n√£o √© confi√°vel\n",
    "- **Recomenda√ß√£o**: Janelas de 5 minutos para an√°lise espectral robusta\n",
    "\n",
    "#### 3. Valida√ß√£o Cruzada\n",
    "- **Aten√ß√£o**: Risco de data leakage\n",
    "- **Problema**: M√∫ltiplas janelas do mesmo paciente em treino e teste\n",
    "- **Solu√ß√£o**: Implementar valida√ß√£o cruzada a n√≠vel de paciente\n",
    "\n",
    "### Trabalhos Futuros\n",
    "\n",
    "1. **Expandir Dataset**: Incluir todos os registros dispon√≠veis\n",
    "2. **Valida√ß√£o por Paciente**: Implementar Leave-One-Patient-Out CV\n",
    "3. **An√°lise de Janelas Maiores**: Testar com 5 minutos para an√°lise espectral\n",
    "4. **Explorar IC3 Detalhadamente**: Visualizar e entender o que foi isolado\n",
    "5. **Testar Outros Classificadores**: Random Forest, SVM, Redes Neurais\n",
    "6. **Detec√ß√£o em Tempo Real**: Adaptar para streaming de ECG\n",
    "\n",
    "---\n",
    "\n",
    "## üìö 13. Refer√™ncias\n",
    "\n",
    "### Bases de Dados\n",
    "- **MIT-BIH Normal Sinus Rhythm Database**: Goldberger et al., PhysioNet\n",
    "- **MIT-BIH Atrial Fibrillation Database**: Moody & Mark, PhysioNet\n",
    "\n",
    "### M√©todos\n",
    "- **An√°lise HRV**: Task Force Guidelines (1996)\n",
    "- **PCA em ECG**: Transforma√ß√µes lineares para an√°lise morfol√≥gica\n",
    "- **ICA em ECG**: Separa√ß√£o cega de fontes para remo√ß√£o de artefatos\n",
    "- **XGBoost**: Chen & Guestrin (2016)\n",
    "\n",
    "### Ferramentas\n",
    "- **WFDB Python**: Biblioteca para processamento de sinais fisiol√≥gicos\n",
    "- **scikit-learn**: Ferramentas de machine learning\n",
    "- **XGBoost**: Gradient boosting otimizado\n",
    "\n",
    "---\n",
    "\n",
    "## üôè Agradecimentos\n",
    "\n",
    "Obrigado pela aten√ß√£o!\n",
    "\n",
    "**Contato**: [Seu email/informa√ß√µes]  \n",
    "**C√≥digo**: [Link do GitHub]\n",
    "\n",
    "---\n",
    "\n",
    "### üíª Ambiente T√©cnico\n",
    "- Python 3.x\n",
    "- Principais bibliotecas: wfdb, scikit-learn, xgboost, pandas, numpy, matplotlib, seaborn\n",
    "- Processamento de sinais: scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034a84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula final para gerar um resumo executivo\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 15 + \"RESUMO EXECUTIVO DO PROJETO\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìä DADOS\")\n",
    "print(f\"   ‚Ä¢ Pacientes: 10 (5 Normal + 5 AFib)\")\n",
    "print(f\"   ‚Ä¢ Amostras totais: {len(df_comprehensive)}\")\n",
    "print(f\"   ‚Ä¢ Features extra√≠das: {len(all_features)}\")\n",
    "print(f\"\\nüéØ MODELO\")\n",
    "print(f\"   ‚Ä¢ Algoritmo: XGBoost\")\n",
    "print(f\"   ‚Ä¢ Acur√°cia: {accuracy:.1%}\")\n",
    "print(f\"   ‚Ä¢ AUC Score: {auc_score:.3f}\")\n",
    "print(f\"   ‚Ä¢ Valida√ß√£o Cruzada: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n",
    "print(f\"\\nüèÜ TOP 3 FEATURES\")\n",
    "for i, (_, row) in enumerate(importance_df.head(3).iterrows(), 1):\n",
    "    print(f\"   {i}. {row['feature']}: {row['importance']:.4f}\")\n",
    "print(f\"\\n‚úÖ CONCLUS√ÉO\")\n",
    "print(f\"   O modelo demonstra excelente capacidade de distinguir entre\")\n",
    "print(f\"   ritmo sinusal normal e fibrila√ß√£o atrial usando features\")\n",
    "print(f\"   avan√ßadas de processamento de sinais ECG.\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
